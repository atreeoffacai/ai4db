这是一个经过整理、润色和规范化后的完整中文技术报告。报告逻辑严密，语言学术化，涵盖了从问题分析、模型方法、基数估计实验结果到最终优化器集成的完整过程。

---

# 基于深度学习的基数估计修正与查询优化加速研究报告

## 1. 问题背景：基数估计的瓶颈

在现代数据库系统中，基数估计（Cardinality Estimation, CE）的准确度严重不足，已成为查询优化器生成最优执行计划的主要瓶颈。传统的基数估计依赖于直方图统计和属性独立性假设，在面对复杂查询时往往失效。

### 1.1 偏差分布特征

我们在 JOB (Join Order Benchmark) 数据集的 113 个查询执行过程中，收集了涉及基数估计的子查询数据。图一展示了真实基数与预估基数的偏差分布（真实基数/预估基数）。

**分析结论：**

* 数据库系统中的基数估计存在严重失真，且主要表现为**严重低估**。
* 误差分布呈现极度的不规则性，缺乏明显的统计规律，难以使用普通函数进行简单的拟合修正。

### 1.2 误差与查询复杂度的关系

图二展示了基数估计误差与查询复杂度（以涉及表的个数为度量）之间的关系。横坐标为表的个数，纵坐标为误差比例（1.0 代表准确），颜色深度代表数据密度。

**分析结论：**

* 基数估计的误差与查询复杂度之间**没有明显的线性相关性**。
* 即使在固定的查询复杂度（如固定表连接数）下，基数估计的误差波动依然巨大。这表明仅靠查询规模等简单特征无法有效预测或修正误差。

---

## 2. 方法论：基数修正分类模型

鉴于上述分析，我们需要引入外部模型来修正基数估计。传统的**基数预测回归模型**（输入 SQL，直接输出基数值）存在三个主要缺陷：

1. **收敛困难**：模型训练时间长，难以达到稳态。
2. **泛化性差**：缺乏数据库优化器原有的一致性，在测试集表现不佳。
3. **忽略字符串匹配**：现有模型大多忽略 `LIKE` 谓词，导致涉及文本模糊匹配的查询预测效果极差。

为了解决上述问题，本文提出了一种**基数修正分类模型 (Cardinality Correction Classification Model)**。

### 2.1 核心思想：学习误差而非学习基数

该方法不直接建立“查询  基数”的映射，而是学习现有数据库基数估计器的**错误特性**。

* **输入**：`SELECT COUNT()` 开头的 SQL 语句 + 数据库原始预估基数。
* **输出**：一个离散的**缩放因子 (Scaling Factor)**。
* **计算公式**：。

这种设计保留了数据库“专家系统”的部分先验知识，仅让模型负责“纠偏”，从而显著加快了模型的收敛速度。

### 2.2 离散缩放因子的构建

模型预测的是离散类别，而非连续值。为了适配数据库估计“严重低估、轻微高估”的特点，我们基于底数为 10 的等比数列构建分类标签。

每个类别  与索引  的关系为：


其中指数  是一个步长为  的等差数列。这种设计实现了**对数均匀分布 (Log-Uniform Distribution)**：

* **优势**：在对数坐标轴上均匀间隔，既能精细区分较小的修正幅度，又能覆盖极大的误差范围（如  倍到  倍）。
* **步长 () 的权衡**：步长越小，修正越细腻，但分类数量增加，训练资源消耗越大。本文对比了  四种步长。

### 2.3 特征工程：LIKE 谓词的 One-Hot 编码

针对 `LIKE` 谓词这一难点，本文采用了一种高效的特征处理方式：

* 使用 **52位 One-Hot 编码**，分别对应 `a-z` 和 `A-Z`。
* **逻辑**：若某字符出现在 `LIKE` 模式串中，则对应位置 1，否则置 0。
* 虽然这是一种宽泛的匹配（丢失了顺序和通配符位置信息），但鉴于实际业务中用户感兴趣的文本模式是有限的，实验证明这种简单的编码能极大提升模型对模糊查询的理解能力。

---

## 3. 实验评估：基数估计模型质量

我们对比了不同步长的分类模型、回归模型（MSCN变体）以及 PostgreSQL 原生估计器。

### 3.1 训练效率

* **收敛速度**：分类模型的 Loss 曲线比回归模型更早趋于水平，收敛速度显著更快。Step 越大（类别越少），训练越快。
* **训练时长**：回归模型的训练耗时显著高于 Step=0.1/0.2/0.5 的分类模型。

### 3.2 预测质量 (Q-Error)

我们选择兼顾效率与质量的 **Step=0.1 分类模型** 进行详细评估。

1. **总体表现**：
* **PostgreSQL**：平均 Q-Error 高达 **104,672**，中位数 648。
* **回归模型**：平均 Q-Error **4.11**。
* **分类模型 (Step=0.1, 含Like处理)**：平均 Q-Error **5.40**，中位数 **1.68**。
* **结论**：机器学习模型将误差降低了几个数量级。尽管分类模型在极端尾部（95th%）略逊于回归模型，但其中位数表现更优，且训练效率更高。


2. **LIKE 处理的重要性**：
* **含 Like 处理**：平均 Q-Error 5.40。
* **无 Like 处理**：平均 Q-Error **67.86**。
* **结论**：缺乏对 `LIKE` 谓词的特征提取会导致模型性能雪崩式下降。



---

## 4. 应用与集成：动态规划 (DP) 中的影子基数

将模型集成到数据库优化器的动态规划过程中时，对于分类模型，存在**误差累积**的风险：如果直接修改数据库内部的基数，ML 模型在处理上层计划时，会基于已经被放大的子计划基数再次放大，导致基数爆炸。

### 4.1 解决方案：影子基数 (Shadow Cardinality)

我们提出“影子基数”策略：

* **在 DP 过程中维护两套基数**。
* **交互时**：向 ML 模型发送未被修改的、原始的“影子基数”（PostgreSQL 原生估计）。
* **决策时**：优化器使用经过 ML 修正后的“ML 基数”来比较计划代价。

### 4.2 计划质量评估

在 IMDB 数据集上的测试表明：

1. **执行时间**：分类模型（绿色） < 回归模型（蓝色） < PG原生（红色）。分类模型表现出最好的鲁棒性。
2. **保序性 (Rank Correlation)**：
* 在全量测试集上，分类模型的 **Kendall's Tau (0.8625)** 显著优于 PG 原生 (0.4227)，说明其不仅数值准，还能正确判断“哪个计划更好”。
* *注：在部分特定查询（如 9b）中，PG 原生仍保持了较好的相对顺序，但在整体统计上 ML 模型优势明显。*



---

## 5. 进阶优化：基于强化学习 (RL) 的端到端优化

尽管 ML 基数估计提升了计划质量，但在动态规划（DP）模式下，由于需要对成千上万个子计划进行 ML 推理（且涉及 Python-C++ 进程间通信），导致**规划时间 (Planning Time)** 暴涨。

* **Mode 2 (ML-Comm)**：虽然执行时间最短（2.2s），但规划时间平均高达 **15.2s**，不可接受。

### 5.1 方法：强化学习 (RL) 替代动态规划

我们引入 RL (如 DQN/PPO) 来直接生成 Join Order：

* **奖励函数**：SQL 的实际执行时间。
* **优势**：RL 模型在训练后，推理过程的时间复杂度仅为 （ 为表数量），直接锁定 Join Order，**剪枝**了绝大部分搜索空间，从而避免了海量的 ML 基数推理调用。

### 5.2 最终 Benchmark 结果

| 模式 | 规划时间 (Avg) | 执行时间 (Avg) | 总耗时 (Total Sum) | 性能倍数 |
| --- | --- | --- | --- | --- |
| **Mode 1 (Native PG)** | 115 ms | 87,585 ms | 2,017,111 ms | 1.0x |
| **Mode 2 (ML-Comm)** | 15,233 ms | **2,245 ms** | 402,010 ms | 5.0x |
| **Mode 3 (RL Pipeline)** | **406 ms** | 8,624 ms | **207,694 ms** | **10.0x** |

**结论：**

1. **RL 模式 (Mode 3)** 综合表现最佳，相比原生 PG 实现了 **10 倍 (0.10x)** 的总延迟降低。
2. RL 成功规避了 Mode 2 中“全量 ML 基数估计”带来的耗时陷阱，将规划时间从 15s 压缩回 0.4s。
3. 虽然 RL 选出的计划执行时间（8.6s）略慢于全空间搜索的 Mode 2（2.2s），但其极低的规划开销使其成为最具有实用价值的端到端解决方案，尤其在解决长尾慢查询方面效果显著。
